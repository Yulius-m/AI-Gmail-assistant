# üöÄ FIT Group - Multilingual Gmail Assistant

Advanced AI-powered email processing system with GPT-4 integration for automated email analysis, classification, and response generation.

## üåü Key Features

- **Multilingual Processing**: Supports 7+ languages with automatic detection
- **Advanced AI Classification**: 50+ business command categories
- **Dual Reply Generation**: Professional & Friendly tone variations
- **Smart Confidence Scoring**: Automated quality assessment
- **Team Routing**: Automatic assignment to Sales, Support, HR, Legal, etc.
- **Notion Integration**: Seamless workflow logging
- **Real-time Analytics**: Processing statistics and performance metrics

## üìã Prerequisites

### Required Services
1. **OpenAI API Account** - GPT-4 access required
2. **Google Cloud Console** - Gmail API access
3. **Notion Workspace** (Optional) - For workflow integration
4. **Render Account** - For deployment

### API Keys Needed
- OpenAI API Key
- Google Service Account JSON or OAuth Token
- Notion Integration Token (optional)

## üîß Setup Instructions

### 1. Google Cloud Setup

#### Option A: Service Account (Recommended for Production)
1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing
3. Enable Gmail API
4. Create a Service Account:
   - Go to IAM & Admin > Service Accounts
   - Click "Create Service Account"
   - Grant necessary permissions
   - Generate JSON key
5. Enable Domain-Wide Delegation (for G Suite/Workspace):
   - Admin Console > Security > API Controls
   - Add service account client ID with Gmail scope

#### Option B: OAuth Token (Development)
1. Create OAuth 2.0 credentials
2. Download credentials.json
3. Run OAuth flow to get token.json

### 2. Notion Setup (Optional)
1. Create a Notion integration at [notion.so/my-integrations](https://www.notion.so/my-integrations)
2. Create a database with these properties:
   - Email Subject (Title)
   - Sender (Email)
   - Received Date (Date)
   - Language (Select)
   - Summary (Rich Text)
   - Commands (Multi-select)
   - Tone (Select: positive, neutral, negative, urgent, confused)
   - Team Tags (Multi-select)
   - Confidence Score (Number)
   - Action Status (Select)
   - Reply Draft 1 (Rich Text)
   - Reply Draft 2 (Rich Text)
   - Processing Status (Select)
   - Processed At (Date)

3. Share database with your integration

### 3. Render Deployment

#### Method 1: GitHub Integration (Recommended)
1. Fork/clone this repository
2. Push to your GitHub account
3. Connect to Render:
   - Go to [render.com](https://render.com)
   - New > Web Service
   - Connect your GitHub repo
   - Configure environment variables (see below)

#### Method 2: Direct Deploy
1. Create new Web Service on Render
2. Upload project files
3. Set build/start commands

### 4. Environment Variables

Set these in Render Dashboard > Environment:

```bash
# Required
OPENAI_API_KEY=sk-your-openai-key
GMAIL_USER_EMAIL=admin@yourcompany.com

# Google Auth (choose one)
GOOGLE_SERVICE_ACCOUNT_JSON={"type":"service_account",...}
# OR
GOOGLE_OAUTH_TOKEN={"access_token":"...","refresh_token":"..."}

# Optional - Notion Integration
NOTION_TOKEN=secret_your-notion-token
NOTION_DATABASE_ID=your-database-id

# Application Settings
FLASK_ENV=production
DEBUG=false
```

### 5. Build Configuration

Render will use these settings:
- **Build Command**: `pip install -r requirements.txt`
- **Start Command**: `gunicorn --bind 0.0.0.0:$PORT main:app --workers 2 --timeout 120`
- **Python Version**: 3.11.6

## üì° API Endpoints

### Health Check
```http
GET /api/health
```
Returns system status and service connectivity.

### Process Recent Emails
```http
POST /api/process-emails
Content-Type: application/json

{
    "days": 7,
    "max_results": 50
}
```

### Advanced Batch Processing
```http
POST /api/process-batch
Content-Type: application/json

{
    "days": 7,
    "max_results": 50,
    "include_full_data": false
}
```

### System Statistics
```http
GET /api/stats
```

### Test Connections
```http
GET /api/test-connection
```

## üèóÔ∏è Project Structure

```
fit-gmail-assistant/
‚îú‚îÄ‚îÄ main.py                 # Flask web application
‚îú‚îÄ‚îÄ gmail_assistant.py      # Core AI processing logic
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ render.yaml            # Render deployment config
‚îú‚îÄ‚îÄ README.md              # This file
‚îî‚îÄ‚îÄ logs/                  # Application logs (auto-created)
```

## üîí Security Best Practices

1. **API Keys**: Never commit API keys to version control
2. **Environment Variables**: Use Render's secure environment variable storage
3. **Service Accounts**: Prefer service accounts over OAuth for production
4. **Access Control**: Implement proper authentication for production use
5. **Rate Limiting**: Monitor API usage to avoid rate limits

## üöÄ Production Deployment Checklist

- [ ] OpenAI API key configured
- [ ] Google Cloud project setup with Gmail API enabled
- [ ] Service account created with proper permissions
- [ ] Environment variables set in Render
- [ ] Health check endpoint responding
- [ ] Test connection endpoint validates all APIs
- [ ] Notion database configured (if using)
- [ ] Email processing tested with sample data
- [ ] Monitoring and logging configured
- [ ] Domain/subdomain pointed to Render (if needed)

## üìä Monitoring & Analytics

### Key Metrics to Track
- **Processing Success Rate**: Percentage of emails processed successfully
- **Confidence Score Distribution**: Quality of AI-generated responses
- **Language Detection Accuracy**: Multilingual processing effectiveness
- **Team Routing Accuracy**: Correct department assignment
- **API Response Times**: Performance monitoring
- **Error Rates**: System reliability tracking

### Logging
- Application logs stored in `/logs/gmail_assistant.log`
- Structured logging for easy parsing
- Error tracking with stack traces
- Performance metrics logging

## üõ†Ô∏è Troubleshooting

### Common Issues

#### 1. Gmail API Authentication Errors
```
Error: [Errno 2] No such file or directory: 'token.json'
```
**Solution**: Ensure `GOOGLE_SERVICE_ACCOUNT_JSON` or `GOOGLE_OAUTH_TOKEN` is properly set.

#### 2. OpenAI API Rate Limits
```
Error: Rate limit exceeded
```
**Solution**: Implement request queuing or upgrade OpenAI plan.

#### 3. Notion Sync Failures
```
Error: Notion sync failed
```
**Solution**: 
- Verify `NOTION_TOKEN` and `NOTION_DATABASE_ID`
- Check database permissions
- Validate database schema matches expected properties

#### 4. Memory Issues on Render
```
Error: Application exceeded memory limit
```
**Solution**: 
- Reduce `max_results` parameter
- Upgrade to higher Render plan
- Optimize email content processing

### Debug Mode
Enable debug mode for development:
```bash
DEBUG=true
FLASK_ENV=development
```

## üîß Configuration Options

### Email Processing Parameters
- `days`: Number of days to look back (1-30)
- `max_results`: Maximum emails to process (1-100)
- `include_full_data`: Include full email content in API responses

### AI Model Configuration
- Default model: GPT-4
- Temperature settings optimized for business communications
- Token limits configured for efficient processing

### Team Routing Configuration
Teams are automatically assigned based on command detection:
- **Sales**: demos, proposals, partnerships
- **Support**: technical issues, bugs, access requests
- **HR**: applications, interviews, employee queries
- **Finance**: billing, invoices, pricing
- **Legal**: contracts, compliance, privacy
- **Operations**: shipping, inventory, logistics
- **Marketing**: events, content, collaborations

## üìà Scaling Considerations

### Performance Optimization
1. **Batch Processing**: Process multiple emails efficiently
2. **Caching**: Implement Redis for repeated queries
3. **Queue System**: Use Celery for background processing
4. **Database Optimization**: Index Notion database properly

### High-Volume Processing
For processing >1000 emails/day:
1. Upgrade to Render Pro plan
2. Implement worker processes
3. Add database connection pooling
4. Consider microservices architecture

## üß™ Testing

### Local Testing
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export OPENAI_API_KEY=your-key
export GOOGLE_SERVICE_ACCOUNT_JSON='{"type":"service_account",...}'

# Run application
python main.py
```

### API Testing
```bash
# Health check
curl https://your-app.onrender.com/api/health

# Process test emails
curl -X POST https://your-app.onrender.com/api/process-emails \
  -H "Content-Type: application/json" \
  -d '{"days": 1, "max_results": 5}'
```

## üìû Support & Maintenance

### Regular Maintenance Tasks
- [ ] Monitor API key usage and limits
- [ ] Review processing accuracy and adjust prompts
- [ ] Update command taxonomy based on business needs
- [ ] Backup Notion database configurations
- [ ] Monitor application logs for errors

### Performance Monitoring
- Set up Render metrics monitoring
- Configure email alerts for critical failures
- Track processing time trends
- Monitor memory and CPU usage

### Updates and Improvements
- Keep dependencies updated for security
- Regularly review and optimize AI prompts
- Expand language support as needed
- Add new business command categories

## ü§ù Contributing

### Development Workflow
1. Fork the repository
2. Create feature branch
3. Implement changes with tests
4. Submit pull request
5. Review and merge

### Code Standards
- Follow PEP 8 for Python code
- Add docstrings for all functions
- Include error handling
- Write unit tests for new features

## üìÑ License

This project is proprietary to FIT Group. All rights reserved.

## üÜò Emergency Contacts

- **Technical Issues**: aya@fitgroup.cc
- **API Problems**: aya@fitgroup.cc
- **Business Questions**: yang@fitgroup.cc

---

**Built for FIT Group by the AI Engineering Team**

*Last Updated: August 2025*